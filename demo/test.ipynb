{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa5e9b68",
   "metadata": {},
   "source": [
    "### üìå Cell 5: Import Libraries\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt cho d·ª± √°n\n",
    "\n",
    "**Input:** Kh√¥ng c√≥  \n",
    "**Output:** In ra phi√™n b·∫£n OpenCV v√† NumPy\n",
    "\n",
    "**Code l√†m g√¨:**\n",
    "```python\n",
    "import cv2              # OpenCV - x·ª≠ l√Ω video/h√¨nh ·∫£nh\n",
    "import numpy as np      # NumPy - t√≠nh to√°n m·∫£ng\n",
    "import matplotlib.pyplot as plt  # V·∫Ω bi·ªÉu ƒë·ªì\n",
    "from IPython.display import Video, Image, display  # Hi·ªÉn th·ªã media\n",
    "import os               # Thao t√°c file/th∆∞ m·ª•c\n",
    "```\n",
    "\n",
    "**√ù nghƒ©a:**\n",
    "- `cv2`: Th∆∞ vi·ªán ch√≠nh ƒë·ªÉ ƒë·ªçc video, x·ª≠ l√Ω ·∫£nh, detect features\n",
    "- `numpy`: X·ª≠ l√Ω ma tr·∫≠n t·ªça ƒë·ªô ƒëi·ªÉm, t√≠nh to√°n vector\n",
    "- `matplotlib`: V·∫Ω k·∫øt qu·∫£ tracking, bi·ªÉu ƒë·ªì ph√¢n t√≠ch\n",
    "- `IPython.display`: Hi·ªÉn th·ªã video output trong notebook\n",
    "- `os`: Ki·ªÉm tra file t·ªìn t·∫°i, l·∫•y k√≠ch th∆∞·ªõc file\n",
    "\n",
    "**Vai tr√≤:** Chu·∫©n b·ªã c√¥ng c·ª• c·∫ßn thi·∫øt cho to√†n b·ªô d·ª± √°n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589eaece",
   "metadata": {},
   "source": [
    "### üìå Cell 7: Configuration Parameters (C·∫•u h√¨nh tham s·ªë)\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** Thi·∫øt l·∫≠p c√°c tham s·ªë cho thu·∫≠t to√°n KLT\n",
    "\n",
    "**Input:** Kh√¥ng c√≥  \n",
    "**Output:** In \"Configuration loaded successfully!\"\n",
    "\n",
    "**Code l√†m g√¨:**\n",
    "\n",
    "**1. feature_params (Tham s·ªë ph√°t hi·ªán g√≥c):**\n",
    "```python\n",
    "maxCorners=100       # Ph√°t hi·ªán t·ªëi ƒëa 100 g√≥c\n",
    "qualityLevel=0.3     # Ch·ªâ l·∫•y g√≥c c√≥ ch·∫•t l∆∞·ª£ng ‚â• 30%\n",
    "minDistance=7        # C√°c g√≥c c√°ch nhau √≠t nh·∫•t 7 pixels\n",
    "blockSize=7          # K√≠ch th∆∞·ªõc v√πng t√≠nh to√°n g√≥c\n",
    "```\n",
    "\n",
    "**2. lk_params (Tham s·ªë Lucas-Kanade):**\n",
    "```python\n",
    "winSize=(15, 15)     # C·ª≠a s·ªï t√¨m ki·∫øm 15x15 pixels\n",
    "maxLevel=2           # D√πng 3 t·∫ßng kim t·ª± th√°p (0,1,2)\n",
    "criteria=(...)       # D·ª´ng sau 10 l·∫ßn l·∫∑p ho·∫∑c ƒë·ªô ch√≠nh x√°c 0.03\n",
    "```\n",
    "\n",
    "**3. VIDEO_INPUT/OUTPUT:**\n",
    "```python\n",
    "VIDEO_INPUT = \"Easy.mp4\"                    # File video ƒë·∫ßu v√†o\n",
    "VIDEO_OUTPUT = \"klt_tracking_output.avi\"    # File video ƒë·∫ßu ra\n",
    "DISPLAY_REALTIME = False                    # C√≥ hi·ªÉn th·ªã real-time kh√¥ng\n",
    "FEATURE_REFRESH_THRESHOLD = 15              # T√°i t·∫°o features khi < 15 ƒëi·ªÉm\n",
    "```\n",
    "\n",
    "**√ù nghƒ©a:**\n",
    "- `maxCorners`: C√†ng nhi·ªÅu ‚Üí track nhi·ªÅu ƒëi·ªÉm h∆°n nh∆∞ng ch·∫≠m h∆°n\n",
    "- `qualityLevel`: C√†ng cao ‚Üí ch·ªçn g√≥c m·∫°nh h∆°n, √≠t false positive\n",
    "- `minDistance`: Tr√°nh c√°c ƒëi·ªÉm qu√° g·∫ßn nhau, ph√¢n b·ªë ƒë·ªÅu h∆°n\n",
    "- `winSize`: L·ªõn h∆°n ‚Üí track displacement l·ªõn nh∆∞ng ch·∫≠m h∆°n\n",
    "- `maxLevel`: T·∫ßng cao h∆°n ‚Üí track chuy·ªÉn ƒë·ªông nhanh t·ªët h∆°n\n",
    "\n",
    "**Vai tr√≤:** ƒêi·ªÅu ch·ªânh ƒë·ªô nh·∫°y v√† hi·ªáu su·∫•t c·ªßa thu·∫≠t to√°n tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a40fb5",
   "metadata": {},
   "source": [
    "### üìå Cell 9: Main KLT Tracking Function (H√†m ch√≠nh)\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** H√†m th·ª±c hi·ªán to√†n b·ªô qu√° tr√¨nh tracking KLT\n",
    "\n",
    "**Input:**\n",
    "- `video_path`: ƒê∆∞·ªùng d·∫´n video (VD: \"Easy.mp4\")\n",
    "- `output_path`: N∆°i l∆∞u video k·∫øt qu·∫£\n",
    "- `display`: True/False - hi·ªÉn th·ªã real-time\n",
    "- `feature_refresh_threshold`: Ng∆∞·ª°ng t√°i t·∫°o features\n",
    "\n",
    "**Output:**\n",
    "- `frames_with_tracking`: Danh s√°ch frames ƒë√£ v·∫Ω tracking\n",
    "- `statistics`: Th·ªëng k√™ (s·ªë frames, s·ªë l·∫ßn refresh, fps...)\n",
    "\n",
    "**Code l√†m g√¨ (t·ª´ng b∆∞·ªõc):**\n",
    "\n",
    "**B∆Ø·ªöC 1: M·ªü video v√† l·∫•y th√¥ng tin**\n",
    "```python\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)      # L·∫•y FPS\n",
    "width = cap.get(...)                  # L·∫•y chi·ªÅu r·ªông\n",
    "height = cap.get(...)                 # L·∫•y chi·ªÅu cao\n",
    "total_frames = cap.get(...)           # T·ªïng s·ªë frames\n",
    "```\n",
    "‚Üí Bi·∫øt video c√≥ bao nhi√™u frames, k√≠ch th∆∞·ªõc bao nhi√™u\n",
    "\n",
    "**B∆Ø·ªöC 2: T·∫°o VideoWriter ƒë·ªÉ l∆∞u k·∫øt qu·∫£**\n",
    "```python\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "```\n",
    "‚Üí Chu·∫©n b·ªã ƒë·ªÉ ghi video output\n",
    "\n",
    "**B∆Ø·ªöC 3: ƒê·ªçc frame ƒë·∫ßu v√† detect features**\n",
    "```python\n",
    "old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "old_points = cv2.goodFeaturesToTrack(old_gray, **feature_params)\n",
    "```\n",
    "‚Üí Chuy·ªÉn sang ·∫£nh x√°m v√† t√¨m 100 g√≥c m·∫°nh nh·∫•t\n",
    "\n",
    "**B∆Ø·ªöC 4: V√≤ng l·∫∑p tracking (CORE ALGORITHM)**\n",
    "```python\n",
    "while True:\n",
    "    # 4.1: ƒê·ªçc frame m·ªõi\n",
    "    new_frame = cap.read()\n",
    "    new_gray = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 4.2: T√≠nh optical flow (T√åM ƒêI·ªÇM M·ªöI)\n",
    "    new_points, status, error = cv2.calcOpticalFlowPyrLK(\n",
    "        old_gray, new_gray, old_points, None, **lk_params\n",
    "    )\n",
    "    # ‚Üí new_points: V·ªã tr√≠ m·ªõi c·ªßa c√°c ƒëi·ªÉm\n",
    "    # ‚Üí status: 1=t√¨m ƒë∆∞·ª£c, 0=m·∫•t d·∫•u\n",
    "    \n",
    "    # 4.3: L·ªçc ƒëi·ªÉm t·ªët\n",
    "    good_new = new_points[status == 1]  # Ch·ªâ l·∫•y ƒëi·ªÉm track ƒë∆∞·ª£c\n",
    "    good_old = old_points[status == 1]\n",
    "    \n",
    "    # 4.4: V·∫º MOTION VECTORS (Quiver plot)\n",
    "    for new, old in zip(good_new, good_old):\n",
    "        # V·∫Ω ƒë∆∞·ªùng th·∫≥ng t·ª´ v·ªã tr√≠ c≈© ‚Üí m·ªõi\n",
    "        mask = cv2.line(mask, (old_x, old_y), (new_x, new_y), color, 2)\n",
    "        # V·∫Ω ch·∫•m tr√≤n t·∫°i v·ªã tr√≠ hi·ªán t·∫°i\n",
    "        frame = cv2.circle(frame, (new_x, new_y), 5, color, -1)\n",
    "    \n",
    "    # 4.5: Gh√©p frame + motion trails\n",
    "    output_frame = cv2.add(new_frame, mask)\n",
    "    \n",
    "    # 4.6: C·∫¨P NH·∫¨T cho frame ti·∫øp theo\n",
    "    old_gray = new_gray\n",
    "    old_points = good_new\n",
    "    \n",
    "    # 4.7: T√ÅI T·∫†O FEATURES n·∫øu m·∫•t qu√° nhi·ªÅu\n",
    "    if len(good_new) < 15:\n",
    "        old_points = cv2.goodFeaturesToTrack(new_gray, ...)\n",
    "        mask = np.zeros_like(old_frame)  # X√≥a trails\n",
    "```\n",
    "\n",
    "**B∆Ø·ªöC 5: D·ªçn d·∫πp v√† tr·∫£ v·ªÅ k·∫øt qu·∫£**\n",
    "```python\n",
    "cap.release()\n",
    "out.release()\n",
    "return frames_with_tracking, statistics\n",
    "```\n",
    "\n",
    "**√ù nghƒ©a:**\n",
    "- **calcOpticalFlowPyrLK**: Tr√°i tim c·ªßa KLT, t√¨m ƒëi·ªÉm di chuy·ªÉn ƒë·∫øn ƒë√¢u\n",
    "- **Pyramidal**: X·ª≠ l√Ω nhi·ªÅu scale ‚Üí track chuy·ªÉn ƒë·ªông nhanh t·ªët h∆°n\n",
    "- **Feature refresh**: Khi m·∫•t qu√° nhi·ªÅu ƒëi·ªÉm ‚Üí detect l·∫°i ƒë·ªÉ ti·∫øp t·ª•c\n",
    "\n",
    "**Vai tr√≤:** Th·ª±c hi·ªán to√†n b·ªô quy tr√¨nh KLT tracking t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e334c6",
   "metadata": {},
   "source": [
    "### üìå Cell 11: Run KLT Tracking (Ch·∫°y tracking)\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** G·ªçi h√†m KLT ƒë·ªÉ x·ª≠ l√Ω video\n",
    "\n",
    "**Input:**\n",
    "- `VIDEO_INPUT` = \"Easy.mp4\"\n",
    "- `VIDEO_OUTPUT` = \"klt_tracking_output.avi\"\n",
    "- `DISPLAY_REALTIME` = False\n",
    "- `FEATURE_REFRESH_THRESHOLD` = 15\n",
    "\n",
    "**Output:**\n",
    "- Video ƒë∆∞·ª£c l∆∞u v√†o `klt_tracking_output.avi`\n",
    "- `frames`: List ch·ª©a t·∫•t c·∫£ frames ƒë√£ tracking\n",
    "- `stats`: Dict th·ªëng k√™ (total_frames, feature_refreshes, fps...)\n",
    "- In ra console: \"Tracking completed successfully!\"\n",
    "\n",
    "**Code l√†m g√¨:**\n",
    "```python\n",
    "frames, stats = klt_feature_tracking(\n",
    "    video_path=VIDEO_INPUT,\n",
    "    output_path=VIDEO_OUTPUT,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "**Qu√° tr√¨nh th·ª±c t·∫ø:**\n",
    "1. ƒê·ªçc video Easy.mp4 (c√≥ th·ªÉ 200-400 frames)\n",
    "2. Detect 100 features ·ªü frame ƒë·∫ßu\n",
    "3. Track qua t·ª´ng frame, v·∫Ω motion vectors\n",
    "4. Khi features < 15 ‚Üí detect l·∫°i\n",
    "5. L∆∞u t·∫•t c·∫£ v√†o file .avi\n",
    "6. M·∫•t ~30 gi√¢y - 2 ph√∫t t√πy video\n",
    "\n",
    "**√ù nghƒ©a:** ƒê√¢y l√† cell quan tr·ªçng nh·∫•t - th·ª±c thi to√†n b·ªô thu·∫≠t to√°n\n",
    "\n",
    "**Vai tr√≤:** Bi·∫øn l√Ω thuy·∫øt th√†nh k·∫øt qu·∫£ th·ª±c t·∫ø (video output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32903a24",
   "metadata": {},
   "source": [
    "### üìå Cell 13: Display Sample Frames (Hi·ªÉn th·ªã frames m·∫´u)\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** Xem m·ªôt s·ªë frames ƒë·∫°i di·ªán t·ª´ video tracking\n",
    "\n",
    "**Input:**\n",
    "- `frames`: List frames t·ª´ cell 11 (VD: 200 frames)\n",
    "\n",
    "**Output:**\n",
    "- Figure 2x3 v·ªõi 5 frames: ƒë·∫ßu, 1/4, gi·ªØa, 3/4, cu·ªëi\n",
    "- File ·∫£nh: `klt_tracking_samples.png`\n",
    "\n",
    "**Code l√†m g√¨:**\n",
    "```python\n",
    "# Ch·ªçn 5 frames ƒë·∫°i di·ªán\n",
    "sample_indices = [0, len(frames)//4, len(frames)//2, 3*len(frames)//4, len(frames)-1]\n",
    "# VD: [0, 50, 100, 150, 199]\n",
    "\n",
    "# V·∫Ω t·ª´ng frame\n",
    "for idx, frame_idx in enumerate(sample_indices):\n",
    "    frame_rgb = cv2.cvtColor(frames[frame_idx], cv2.COLOR_BGR2RGB)\n",
    "    axes[idx].imshow(frame_rgb)\n",
    "    axes[idx].set_title(f'Frame {frame_idx+1}')\n",
    "\n",
    "plt.savefig('klt_tracking_samples.png')\n",
    "```\n",
    "\n",
    "**√ù nghƒ©a:**\n",
    "- Th·∫•y ƒë∆∞·ª£c tracking ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o qua th·ªùi gian\n",
    "- Ki·ªÉm tra xem features c√≥ b·ªã m·∫•t kh√¥ng\n",
    "- So s√°nh frame ƒë·∫ßu vs cu·ªëi ‚Üí ƒë·ªô drift\n",
    "\n",
    "**V√≠ d·ª• output:**\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Frame 1 ‚îÇ Frame 51‚îÇ Frame101‚îÇ  ‚Üê ƒê·∫ßu ‚Üí Gi·ªØa\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇFrame151 ‚îÇFrame199 ‚îÇ  (r·ªóng) ‚îÇ  ‚Üê 3/4 ‚Üí Cu·ªëi\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Vai tr√≤:** Visualization ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e486823",
   "metadata": {},
   "source": [
    "### üìå Cell 18: Compare Shi-Tomasi vs Harris (So s√°nh 2 detector)\n",
    "\n",
    "**M·ª•c ƒë√≠ch:** So s√°nh 2 ph∆∞∆°ng ph√°p ph√°t hi·ªán g√≥c\n",
    "\n",
    "**Input:**\n",
    "- Frame ƒë·∫ßu ti√™n c·ªßa video\n",
    "- `feature_params` (tham s·ªë Shi-Tomasi)\n",
    "\n",
    "**Output:**\n",
    "- 3 ·∫£nh: Original | Shi-Tomasi | Harris\n",
    "- File: `feature_comparison.png`\n",
    "- In s·ªë features detect ƒë∆∞·ª£c\n",
    "\n",
    "**Code l√†m g√¨:**\n",
    "```python\n",
    "# Shi-Tomasi (m·∫∑c ƒë·ªãnh)\n",
    "corners_shi = cv2.goodFeaturesToTrack(gray, **feature_params)\n",
    "\n",
    "# Harris (th√™m tham s·ªë useHarrisDetector)\n",
    "harris_params = feature_params.copy()\n",
    "harris_params['useHarrisDetector'] = True\n",
    "harris_params['k'] = 0.04\n",
    "corners_harris = cv2.goodFeaturesToTrack(gray, **harris_params)\n",
    "\n",
    "# V·∫Ω ch·∫•m tr√≤n l√™n c√°c g√≥c detect ƒë∆∞·ª£c\n",
    "for corner in corners_shi:\n",
    "    cv2.circle(frame, (x, y), 5, (0,255,0), -1)  # Xanh l√°\n",
    "for corner in corners_harris:\n",
    "    cv2.circle(frame, (x, y), 5, (255,0,0), -1)  # ƒê·ªè\n",
    "```\n",
    "\n",
    "**√ù nghƒ©a:**\n",
    "\n",
    "**Shi-Tomasi (Good Features to Track):**\n",
    "- T·ªëi ∆∞u cho tracking\n",
    "- Ch·ªçn g√≥c \"d·ªÖ track\" nh·∫•t\n",
    "- Response function: R = min(Œª‚ÇÅ, Œª‚ÇÇ)\n",
    "\n",
    "**Harris Corner Detector:**\n",
    "- Detector c·ªï ƒëi·ªÉn h∆°n\n",
    "- Response function: R = Œª‚ÇÅŒª‚ÇÇ - k(Œª‚ÇÅ + Œª‚ÇÇ)¬≤\n",
    "- Tham s·ªë k ‚âà 0.04-0.06\n",
    "\n",
    "**K·∫øt qu·∫£ th∆∞·ªùng th·∫•y:**\n",
    "- Shi-Tomasi: Detect nhi·ªÅu h∆°n, ph√¢n b·ªë ƒë·ªÅu h∆°n\n",
    "- Harris: Ch·ªçn l·ªçc h∆°n, t·∫≠p trung v√†o g√≥c r·∫•t m·∫°nh\n",
    "\n",
    "**Vai tr√≤:** Hi·ªÉu s·ª± kh√°c bi·ªát gi·ªØa c√°c corner detector"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
